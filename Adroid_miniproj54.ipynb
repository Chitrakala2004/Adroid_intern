{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5547005,
          "sourceType": "datasetVersion",
          "datasetId": 3196060
        }
      ],
      "dockerImageVersionId": 30474,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chitrakala2004/Adroid_intern/blob/main/Adroid_miniproj54.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:33.524757Z",
          "iopub.execute_input": "2023-11-07T09:55:33.525114Z",
          "iopub.status.idle": "2023-11-07T09:55:48.867179Z",
          "shell.execute_reply.started": "2023-11-07T09:55:33.525085Z",
          "shell.execute_reply": "2023-11-07T09:55:48.866028Z"
        },
        "trusted": true,
        "id": "uw0Ycvl28ADF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet2022')\n",
        "\n",
        "! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet # temp fix for lookup error."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:48.869262Z",
          "iopub.execute_input": "2023-11-07T09:55:48.869959Z",
          "iopub.status.idle": "2023-11-07T09:55:50.067251Z",
          "shell.execute_reply.started": "2023-11-07T09:55:48.869928Z",
          "shell.execute_reply": "2023-11-07T09:55:50.065384Z"
        },
        "trusted": true,
        "id": "Ai1h8wao8ADG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/private-hospital-comments/comments1.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.069144Z",
          "iopub.execute_input": "2023-11-07T09:55:50.069503Z",
          "iopub.status.idle": "2023-11-07T09:55:50.151756Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.069457Z",
          "shell.execute_reply": "2023-11-07T09:55:50.150316Z"
        },
        "trusted": true,
        "id": "VOaA6PuL8ADH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Main Topic\"] = df[\"Main Topic\"].fillna(\"No Topic Given\")\n",
        "df = df.dropna(subset=[\"Content\"])\n",
        "nan_counts = df.isna().sum()\n",
        "\n",
        "print(nan_counts)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.154825Z",
          "iopub.execute_input": "2023-11-07T09:55:50.155157Z",
          "iopub.status.idle": "2023-11-07T09:55:50.190464Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.155122Z",
          "shell.execute_reply": "2023-11-07T09:55:50.189476Z"
        },
        "trusted": true,
        "id": "Nc934wqJ8ADI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining regex patterns.\n",
        "linebreaks        = \"<br /><br />\"\n",
        "alphaPattern      = \"[^a-z0-9<>]\"\n",
        "sequencePattern   = r\"(.)\\1\\1+\"\n",
        "seqReplacePattern = r\"\\1\\1\"\n",
        "\n",
        "# Defining regex for emojis\n",
        "smileemoji        = r\"[8:=;]['`\\-]?[)d]+\"\n",
        "sademoji          = r\"[8:=;]['`\\-]?\\(+\"\n",
        "neutralemoji      = r\"[8:=;]['`\\-]?[\\/|l*]\"\n",
        "lolemoji          = r\"[8:=;]['`\\-]?p+\"\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "Lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.192212Z",
          "iopub.execute_input": "2023-11-07T09:55:50.192682Z",
          "iopub.status.idle": "2023-11-07T09:55:50.202427Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.192634Z",
          "shell.execute_reply": "2023-11-07T09:55:50.200425Z"
        },
        "trusted": true,
        "id": "GUQCnX228ADI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_reviews(review):\n",
        "\n",
        "    review = review.lower()\n",
        "\n",
        "    review = re.sub(linebreaks,\" \",review)\n",
        "    # Replace 3 or more consecutive letters by 2 letter.\n",
        "    review = re.sub(sequencePattern, seqReplacePattern, review)\n",
        "\n",
        "    # Replace all emojis.\n",
        "    review = re.sub(r'<3', '<heart>', review)\n",
        "    review = re.sub(smileemoji, '<smile>', review)\n",
        "    review = re.sub(sademoji, '<sadface>', review)\n",
        "    review = re.sub(neutralemoji, '<neutralface>', review)\n",
        "    review = re.sub(lolemoji, '<lolface>', review)\n",
        "\n",
        "    # Remove non-alphanumeric and symbols\n",
        "    review = re.sub(alphaPattern, ' ', review)\n",
        "\n",
        "    # Tokenize the input text\n",
        "    tokens = word_tokenize(review)\n",
        "\n",
        "    # Remove stop words from the token sequence\n",
        "\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize the remaining tokens\n",
        "    tokens = [Lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the cleaned tokens into a single string\n",
        "    return ' '.join(tokens)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.204333Z",
          "iopub.execute_input": "2023-11-07T09:55:50.205333Z",
          "iopub.status.idle": "2023-11-07T09:55:50.215508Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.205288Z",
          "shell.execute_reply": "2023-11-07T09:55:50.213895Z"
        },
        "trusted": true,
        "id": "ZWpKmktC8ADI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine \"Main Topic\", \"Subtopic\", and \"Content\" columns into a single column called \"Text\"\n",
        "df[\"Text\"] = df[\"Main Topic\"] + \" \" + df[\"Subtopic\"] + \" \" + df[\"Content\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.21697Z",
          "iopub.execute_input": "2023-11-07T09:55:50.217296Z",
          "iopub.status.idle": "2023-11-07T09:55:50.240056Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.217271Z",
          "shell.execute_reply": "2023-11-07T09:55:50.238887Z"
        },
        "trusted": true,
        "id": "8Yb71E7q8ADJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Text\"] = df[\"Text\"].apply(preprocess_reviews)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:50.241715Z",
          "iopub.execute_input": "2023-11-07T09:55:50.242093Z",
          "iopub.status.idle": "2023-11-07T09:55:54.204627Z",
          "shell.execute_reply.started": "2023-11-07T09:55:50.242061Z",
          "shell.execute_reply": "2023-11-07T09:55:54.20287Z"
        },
        "trusted": true,
        "id": "0LbUqN098ADJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/towardsNLP/IMDB-Semantic-Sentiment-Analysis/main/Word2Vec/src/w2v_utils.py -o w2v_utils.py"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:54.206233Z",
          "iopub.execute_input": "2023-11-07T09:55:54.206613Z",
          "iopub.status.idle": "2023-11-07T09:55:54.663724Z",
          "shell.execute_reply.started": "2023-11-07T09:55:54.206579Z",
          "shell.execute_reply": "2023-11-07T09:55:54.662839Z"
        },
        "trusted": true,
        "id": "Af1wUEGk8ADJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from w2v_utils import (Tokenizer,\n",
        "                       evaluate_model,\n",
        "                       bow_vectorizer,\n",
        "                       train_logistic_regressor,\n",
        "                       w2v_trainer,\n",
        "                       calculate_overall_similarity_score,\n",
        "                       overall_semantic_sentiment_analysis,\n",
        "                       list_similarity,\n",
        "                       calculate_topn_similarity_score,\n",
        "                       topn_semantic_sentiment_analysis,\n",
        "                       define_complexity_subjectivity_reviews,\n",
        "                       explore_high_complexity_reviews,\n",
        "                       explore_low_subjectivity_reviews,\n",
        "                       text_SSA)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:54.668957Z",
          "iopub.execute_input": "2023-11-07T09:55:54.669325Z",
          "iopub.status.idle": "2023-11-07T09:55:55.849624Z",
          "shell.execute_reply.started": "2023-11-07T09:55:54.669296Z",
          "shell.execute_reply": "2023-11-07T09:55:55.848317Z"
        },
        "trusted": true,
        "id": "vjLt_3DP8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instancing the Tokenizer class\n",
        "tokenizer = Tokenizer(clean= True,\n",
        "                      lower= True,\n",
        "                      de_noise= True,\n",
        "                      remove_stop_words= True,\n",
        "                      keep_negation=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:55.851215Z",
          "iopub.execute_input": "2023-11-07T09:55:55.851602Z",
          "iopub.status.idle": "2023-11-07T09:55:55.857396Z",
          "shell.execute_reply.started": "2023-11-07T09:55:55.85157Z",
          "shell.execute_reply": "2023-11-07T09:55:55.856281Z"
        },
        "trusted": true,
        "id": "Z93mFPxo8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized_text'] = df['Text'].apply(tokenizer.tokenize)\n",
        "\n",
        "df['tokenized_text_len'] = df['tokenized_text'].apply(len)\n",
        "df['tokenized_text_len'].apply(np.log).describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:55.858669Z",
          "iopub.execute_input": "2023-11-07T09:55:55.858966Z",
          "iopub.status.idle": "2023-11-07T09:55:56.454563Z",
          "shell.execute_reply.started": "2023-11-07T09:55:55.858939Z",
          "shell.execute_reply": "2023-11-07T09:55:56.452946Z"
        },
        "trusted": true,
        "id": "rOE6N9wd8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors , keyed_vocab = w2v_trainer(df[\"tokenized_text\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:56.455988Z",
          "iopub.execute_input": "2023-11-07T09:55:56.456264Z",
          "iopub.status.idle": "2023-11-07T09:55:58.235402Z",
          "shell.execute_reply.started": "2023-11-07T09:55:56.45624Z",
          "shell.execute_reply": "2023-11-07T09:55:58.234141Z"
        },
        "trusted": true,
        "id": "FPnAjUaM8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(keyed_vectors))\n",
        "print(type(keyed_vocab))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.236544Z",
          "iopub.execute_input": "2023-11-07T09:55:58.236768Z",
          "iopub.status.idle": "2023-11-07T09:55:58.242238Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.236746Z",
          "shell.execute_reply": "2023-11-07T09:55:58.241279Z"
        },
        "trusted": true,
        "id": "vYuZzMWv8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"research\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.243399Z",
          "iopub.execute_input": "2023-11-07T09:55:58.243638Z",
          "iopub.status.idle": "2023-11-07T09:55:58.259387Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.243615Z",
          "shell.execute_reply": "2023-11-07T09:55:58.258489Z"
        },
        "trusted": true,
        "id": "Rsr95bJt8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"hospital\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.260863Z",
          "iopub.execute_input": "2023-11-07T09:55:58.261388Z",
          "iopub.status.idle": "2023-11-07T09:55:58.269902Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.261356Z",
          "shell.execute_reply": "2023-11-07T09:55:58.268904Z"
        },
        "trusted": true,
        "id": "yyhQiMmp8ADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"funded\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.271485Z",
          "iopub.execute_input": "2023-11-07T09:55:58.272085Z",
          "iopub.status.idle": "2023-11-07T09:55:58.27922Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.272057Z",
          "shell.execute_reply": "2023-11-07T09:55:58.27842Z"
        },
        "trusted": true,
        "id": "Gl7IFqU38ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To make sure that all `positive_concepts` are in the keyed word2vec vocabulary\n",
        "positive_concepts = ['excellent', 'awesome', 'cool','decent','amazing', 'strong', 'good', 'great', 'funny', 'entertaining']\n",
        "pos_concepts = [concept for concept in positive_concepts if concept in keyed_vocab]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.280718Z",
          "iopub.execute_input": "2023-11-07T09:55:58.281355Z",
          "iopub.status.idle": "2023-11-07T09:55:58.285791Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.281327Z",
          "shell.execute_reply": "2023-11-07T09:55:58.284995Z"
        },
        "trusted": true,
        "id": "ILZ3ww0T8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To make sure that all `negative_concepts` are in the keyed word2vec vocabulary\n",
        "negative_concepts = ['terrible','awful','horrible','boring','bad', 'disappointing', 'weak', 'poor',  'senseless','confusing']\n",
        "neg_concepts = [concept for concept in negative_concepts if concept in keyed_vocab]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.287125Z",
          "iopub.execute_input": "2023-11-07T09:55:58.287694Z",
          "iopub.status.idle": "2023-11-07T09:55:58.295869Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.287668Z",
          "shell.execute_reply": "2023-11-07T09:55:58.295098Z"
        },
        "trusted": true,
        "id": "h51gFFxK8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Semantic Sentiment Scores by OSSA model\n",
        "overall_df_scores = overall_semantic_sentiment_analysis (keyed_vectors = keyed_vectors,\n",
        "                                                   positive_target_tokens = pos_concepts,\n",
        "                                                   negative_target_tokens = neg_concepts,\n",
        "                                                   doc_tokens = df['tokenized_text'])\n",
        "\n",
        "# Calculating Semantic Sentiment Scores by TopSSA model\n",
        "topn_df_scores = topn_semantic_sentiment_analysis (keyed_vectors = keyed_vectors,\n",
        "                                                   positive_target_tokens = pos_concepts,\n",
        "                                                   negative_target_tokens = neg_concepts,\n",
        "                                                   doc_tokens = df['tokenized_text'],\n",
        "                                                     topn=30)\n",
        "\n",
        "\n",
        "# To store semantic sentiment store computed by OSSA model in df\n",
        "df['overall_PSS'] = overall_df_scores[0]\n",
        "df['overall_NSS'] = overall_df_scores[1]\n",
        "df['overall_semantic_sentiment_score'] = overall_df_scores[2]\n",
        "df['overall_semantic_sentiment_polarity'] = overall_df_scores[3]\n",
        "\n",
        "\n",
        "\n",
        "# To store semantic sentiment store computed by TopSSA model in df\n",
        "df['topn_PSS'] = topn_df_scores[0]\n",
        "df['topn_NSS'] = topn_df_scores[1]\n",
        "df['topn_semantic_sentiment_score'] = topn_df_scores[2]\n",
        "df['topn_semantic_sentiment_polarity'] = topn_df_scores[3]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:55:58.297252Z",
          "iopub.execute_input": "2023-11-07T09:55:58.297879Z",
          "iopub.status.idle": "2023-11-07T09:56:02.579556Z",
          "shell.execute_reply.started": "2023-11-07T09:55:58.297817Z",
          "shell.execute_reply": "2023-11-07T09:56:02.57825Z"
        },
        "trusted": true,
        "id": "JM0aWYM_8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = keyed_vectors.index_to_key\n",
        "vectors = [keyed_vectors[word] for word in words]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:02.580676Z",
          "iopub.execute_input": "2023-11-07T09:56:02.580992Z",
          "iopub.status.idle": "2023-11-07T09:56:02.593838Z",
          "shell.execute_reply.started": "2023-11-07T09:56:02.580967Z",
          "shell.execute_reply": "2023-11-07T09:56:02.592746Z"
        },
        "trusted": true,
        "id": "zQuy2iCi8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(vectors)\n",
        "\n",
        "# Create a DataFrame with PCA results and words\n",
        "pca_df = pd.DataFrame(result, columns=['x', 'y'])\n",
        "pca_df['word'] = words\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:02.596677Z",
          "iopub.execute_input": "2023-11-07T09:56:02.59702Z",
          "iopub.status.idle": "2023-11-07T09:56:02.720379Z",
          "shell.execute_reply.started": "2023-11-07T09:56:02.596993Z",
          "shell.execute_reply": "2023-11-07T09:56:02.719671Z"
        },
        "trusted": true,
        "id": "2NkuVzKD8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "fig = go.Figure(data=go.Scattergl(\n",
        "    x=pca_df['x'],\n",
        "    y=pca_df['y'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        colorscale='Viridis',\n",
        "        line_width=1\n",
        "    ),\n",
        "    text=pca_df['word'],\n",
        "    textposition=\"bottom center\"\n",
        "))\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:02.721619Z",
          "iopub.execute_input": "2023-11-07T09:56:02.722034Z",
          "iopub.status.idle": "2023-11-07T09:56:02.967894Z",
          "shell.execute_reply.started": "2023-11-07T09:56:02.722007Z",
          "shell.execute_reply": "2023-11-07T09:56:02.965725Z"
        },
        "trusted": true,
        "id": "RPpCihoq8ADL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_pos_filt = df['topn_semantic_sentiment_polarity'] == 1\n",
        "actual_neg_filt =  df['topn_semantic_sentiment_polarity'] == 0\n",
        "\n",
        "# filter positive and negative review based on Most Probable predicted 'y' or 'topn_semantic_sentiment_score' column\n",
        "predicted_pos_filt = df['topn_semantic_sentiment_polarity'] == 1\n",
        "predicted_neg_filt = df['topn_semantic_sentiment_polarity'] == 0\n",
        "\n",
        "\n",
        "\n",
        "# plotting Semantic Sentiment Score Position of Actual Negative Reviews\n",
        "plt.scatter(df['topn_NSS'][actual_neg_filt],\n",
        "         df['topn_PSS'][actual_neg_filt],\n",
        "         label='Actual Negetive Reviews',\n",
        "           color='DarkRed',\n",
        "            alpha=0.4 , # set transparency of color\n",
        "            s=20 # set size of dots\n",
        "           )\n",
        "\n",
        "# plotting Semantic Sentiment Score Position of Actual Positive Reviews\n",
        "plt.scatter(df['topn_NSS'][actual_pos_filt],\n",
        "         df['topn_PSS'][actual_pos_filt],\n",
        "         label='Actual Positive Reviews',\n",
        "       color='DarkGreen',\n",
        "            alpha=0.1, # set transparency of color\n",
        "            s=30 # set size of dots\n",
        "           )\n",
        "# naming the x & y axis\n",
        "plt.xlabel('Predicted Negative Labels')\n",
        "plt.ylabel('Predicted Positive Labels')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:02.970145Z",
          "iopub.execute_input": "2023-11-07T09:56:02.973198Z",
          "iopub.status.idle": "2023-11-07T09:56:03.633102Z",
          "shell.execute_reply.started": "2023-11-07T09:56:02.973143Z",
          "shell.execute_reply": "2023-11-07T09:56:03.631408Z"
        },
        "trusted": true,
        "id": "vKQH6Xlk8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:03.634405Z",
          "iopub.execute_input": "2023-11-07T09:56:03.634685Z",
          "iopub.status.idle": "2023-11-07T09:56:14.597826Z",
          "shell.execute_reply.started": "2023-11-07T09:56:03.634662Z",
          "shell.execute_reply": "2023-11-07T09:56:14.596944Z"
        },
        "trusted": true,
        "id": "jaFRLz2N8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing the pipeline module\n",
        "from transformers import pipeline\n",
        "\n",
        "# Downloading the sentiment analysis model\n",
        "SentimentClassifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Downloading the sentiment analysis model\n",
        "# SentimentClassifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:14.598777Z",
          "iopub.execute_input": "2023-11-07T09:56:14.599108Z",
          "iopub.status.idle": "2023-11-07T09:56:22.78749Z",
          "shell.execute_reply.started": "2023-11-07T09:56:14.599081Z",
          "shell.execute_reply": "2023-11-07T09:56:22.78598Z"
        },
        "trusted": true,
        "id": "S0D2lMSs8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTSentiment(inpText):\n",
        "  return(SentimentClassifier(inpText)[0]['label'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:22.788826Z",
          "iopub.execute_input": "2023-11-07T09:56:22.789141Z",
          "iopub.status.idle": "2023-11-07T09:56:22.794063Z",
          "shell.execute_reply.started": "2023-11-07T09:56:22.789117Z",
          "shell.execute_reply": "2023-11-07T09:56:22.793107Z"
        },
        "trusted": true,
        "id": "Q6Ypr-Tw8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['BERT_Sentiment']=df['Text'].apply(FunctionBERTSentiment)\n",
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-07T09:56:22.799296Z",
          "iopub.execute_input": "2023-11-07T09:56:22.799617Z"
        },
        "trusted": true,
        "id": "myRJDrcw8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTScore(inpText):\n",
        "  return(SentimentClassifier(inpText)[0]['score'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "nOlrm2PX8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Score']=df['Text'].apply(FunctionBERTScore)\n",
        "df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aGRsg8ss8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Content_BERT_Sentiment']=df['Content'].apply(FunctionBERTSentiment)\n",
        "df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xpGQpq8t8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('bert_sentiment.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Cnl2UJ7M8ADM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment analysis of Content + Topic Text\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=df.groupby('BERT_Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fxd7dgcf8ADN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment analysis of Content Only\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=df.groupby('Content_BERT_Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZipkB6J98ADQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}